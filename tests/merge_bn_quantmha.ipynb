{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00e38639-a06e-43e7-bba4-26c29b23a0a2",
   "metadata": {},
   "source": [
    "# Test if merge_bn does not work with any layer from QuantMultiheadAttention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee4e7712-e7e9-47c7-8557-a217ee428199",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from brevitas import nn as qnn\n",
    "from brevitas.nn.utils import merge_bn\n",
    "import qtransform\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "acd21d7a-ac02-4013-835e-ab428b82e574",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "N,C, L = (12, 64, 256)\n",
    "num_heads = 2\n",
    "quant_mha = qnn.QuantMultiheadAttention(num_heads=num_heads, embed_dim=L)\n",
    "bn = torch.nn.BatchNorm1d(C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "21eea839-1015-435a-9762-019c5d5f8f35",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['in_proj',\n",
       " 'out_proj',\n",
       " 'softmax_input_quant',\n",
       " 'attn_output_weights_quant',\n",
       " 'q_scaled_quant',\n",
       " 'k_transposed_quant',\n",
       " 'v_quant']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layers = list(quant_mha._modules.keys())\n",
    "layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12629e57-005b-43b9-b16e-777b1b66ee08",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge_bn updates weight and bias parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4a6d192d-085b-4a1c-a80e-51e323548ea7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passing Layer: in_proj , weight: torch.Size([768, 256]), bias: torch.Size([768])\n",
      "Passing Layer: out_proj , weight: torch.Size([256, 256]), bias: torch.Size([256])\n",
      "Passing Layer: softmax_input_quant \n",
      "Passing Layer: attn_output_weights_quant \n",
      "Passing Layer: q_scaled_quant \n",
      "Passing Layer: k_transposed_quant \n",
      "Passing Layer: v_quant \n",
      "merge_bn worked for: []\n"
     ]
    }
   ],
   "source": [
    "success = list()\n",
    "for layer in layers:\n",
    "    quant_mha_layer = getattr(quant_mha, layer)\n",
    "    print(f'Passing Layer: {layer} ', end=\"\")\n",
    "    try:\n",
    "        print(f', weight: {quant_mha_layer.weight.size()}, bias: {quant_mha_layer.bias.size()}', end=\"\")\n",
    "        merge_bn(quant_mha_layer, bn)\n",
    "        success.append(layer)\n",
    "    except:\n",
    "        pass\n",
    "    print(\"\")\n",
    "print(f'merge_bn worked for: {success}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8ad7363c-1bd8-42f5-88dd-130fb34f0605",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['in_proj', 'out_proj', 'softmax_input_quant', 'attn_output_weights_quant', 'q_scaled_quant', 'k_transposed_quant', 'v_quant'])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c98e8af-b056-48a8-8562-e6defbd1507d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#simulate training\n",
    "prompt = torch.randn(N,C,L)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eki",
   "language": "python",
   "name": "eki"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
