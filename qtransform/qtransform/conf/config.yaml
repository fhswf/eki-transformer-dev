hydra:
  run:
    dir: outputs/${hydra.job.name}/${now:%Y-%m-%d_%H-%M-%S}
  sweep:
    dir: outputs/${hydra.job.name}/${now:%Y-%m-%d_%H-%M-%S}
    subdir: ${hydra.job.num}
  #verbose: [__main__] # only for hydra debug logging, otherwise use debug=True
  searchpath:
    - pkg://qtransform
defaults:
  - _self_
  - model: 
  #use fields from this config, override them with default config from dataset
  - dataset/tokenized: default 
  - dataset/untokenized: default
  - dataset/dataloader: default
  #default config from the lines above are overwritten with specified config
  - dataset:
  - tokenizer: 
  - optim: default
  - optim/scheduler: default
  - run: ???
  - quantization: default
  - override hydra/job_logging: perlevel
  - override hydra/help: main
  #- override hydra/job_logging: colorlog
  #- override hydra/hydra_logging: colorlog

data:
  dtype: 'float32' # 'float32', 'bfloat16', or 'float16'. if llms are used, the dtype has to be supported by torch.Tensor and numpy
device : 'cuda'
debug: False

dataset:
  name: ???
  name_args: #criteria to idenfity dataset (e.g. subset from huggingface dataset)
  root_path: ~/.qtransform/datasets #~/.cache/huggingface/datasets/qtransform/
  #points to the directory containing the dataset used for training/validation etc. 
  #the list is composed of subentries under root_path (root_path included) in hierarchical order
  #the filename of the dataset is not included as it could be split into multiple files (take MNIST for example)
  cache_dir: #directory where tokenized datasets are stored
    - ${dataset.root_path}
    - ${dataset.tokenized.type}
    - ${dataset.name}
    #TODO: include name_args in cache_dir
  cache_filename_prefix: cache-${tokenizer.encoding}-${model.args.block_size} #"cache-gpt2-128. datasetgenerator has their own suffix



tokenizer: 
  encoding: ???
  dtype: ${data.dtype}
  meta_file: meta.pkl #filename of metadata, contains encoding and vocab if character tokenization is used
seed: 1234567890

# DDP settings
#backend : 'nccl' # 'nccl', 'gloo', etc.

model: 
  calc_loss_in_model: False

quantization:
  quantize: False

#filepath of named pipe. currently, the path of saved checkpoints and (q)onnx models are written into it
#by default, write into /dev/null
pipe: /dev/null