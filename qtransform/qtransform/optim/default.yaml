# learning rate decay settings
decay_lr : True # whether to decay the learning rate
warmup_iters : 2000 # how many steps to warm up for
lr_decay_iters : 600000 # should be ~: max_iters per Chinchilla
min_lr : 6e-5 # minimum learning rate, should be ~: learning_rate/10 per Chinchilla
# optimizer
optimizer: AdamW
learning_rate : 1.5e-4 # max learning rate
max_iters : 600000 # total number of training iterations
weight_decay : 1e-1
beta1 : 0.9
beta2 : 0.95
grad_clip : 0.7 # clip gradients at this value, or disable if :: 0.0