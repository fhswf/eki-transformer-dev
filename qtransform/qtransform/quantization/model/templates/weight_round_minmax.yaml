#in this directory, you can define templates for quantization of weights, biases and activations in order to use the same config
#for multiple layers without repeating yourself.

quant_type : INT #Integer, binary, ternary, fixed point integer
bit_width_impl_type : CONST #is the bit width backpropagated and optimised
float_to_int_impl_type : ROUND #how should the quantized values be clipped to fit into the quantized datatype
narrow_range : TRUE #clip max value of data type (e.g. for 8 bits: -128:127 instead of -127:127)
signed : True #can quantized values take on negative values
zero_point_impl : ZeroZeroPoint #how is zero point infered

scaling_impl_type : STATS #how is the scale calculated, for now: statistics

#attributes only applied when scaling_impl_type is statistics
scaling_stats_op : MIN_MAX #max value, minmax etc.
scaling_min_val : 1e-10 #minimum value that the scale is going to have during calibration

scaling_per_output_channel : True #per tensor or per channel quantization
restrict_scaling_type : FP #restrict range of values that scale qparam can have
bit_width : 6 #bit width of quantized values
