
# template for quantization of models 


#idea: iterate through all nn.Module elements within the quant script and manually set the quant parameters based on this yaml config
#problem: apply correct properties to corresponding layer based on name
#problem: call brevitas config efficiently with properties (QuantLinear(**kwargs))
#TODO: translate premade configs from brevitas classes into yaml files 
name: gpt
modules:
  transformer: #name of submodule
    wte: #name of layer
      quantize: True
      kind: weight
      weight: templates/weight_round_minmax.yaml
      #bias: template_bias
    gelu:
      quantize: True
      kind: act
      act: 
        min_value: 0.0
        max_value: 100.0
    another_layer:
      quantize: False