command: infer

num_samples: 10 #generate num_samples 
max_new_tokens: 500
temperature: 0.7
top_k: 200
#start: "My name is Mariam, my favorite" #"\n" #generates text starting with #start (\n, "<|endoftext|>" or etc.) Can also specify a file, use as: "FILE:prompt.txt" where prompt.txt is absolute
#start: "Sara and Ben are playing in the snow. They make a big snowman with a hat and a scarf. They are happy and laugh.\n But then a big dog comes. The dog is angry and barks. He runs to the snowman and bites his hat. Sara and Ben are scared and cry. ”Go away, dog! Leave our snowman alone!” Sara shouts. \n But the dog does not listen. He bites the scarf and the snowman’s nose.\n He shakes his head and makes the snowman fall. Sara and"
start: "<endoftext>One day, a little girl named Lily went to the park with her mom. At the park, Lily saw a big ice-cream truck. She was very excited and wanted to eat ice-cream. She said"
compile: False #use torch.compile

#path of directory create files containing the infered samples. if empty, write onto stdout. 
#the file name is composed as: INFER_<datetime>_<ONNX or CHECKPOINT>.out
out_dir: 

debug: False #use karpathy's inference