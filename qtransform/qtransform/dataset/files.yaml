wrapper: FileSystemLLMDatasetWrapper
#either has to match an entry from links, a dataset from torchvision or a filename (excluding encoding) within dataset directory
name: ??? #directory name, should contain human-readable text files for tokenization
module: files
sizes: #sizes of dataset splits. if omited, assume empty sizes for splits
  train: 0.7
  eval: 0.1
  test: 0.3
  bench: 1.0
args:
  block_size: ${model.args.block_size}
  batches: 1000
  chunking: False #if True, split long sentences after chunk_size characters for faster tokenization. Default: False
  chunk_size: 100 

defaults:
  - dataloader/default
  - tokenizer: tiktoken