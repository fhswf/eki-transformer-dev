wrapper: HuggingfaceDatasetWrapper #name of class within torchvision.py
module: huggingface
name: ???
type: huggingface
sizes: 
  train: 0.3
  eval: 0.05
  test: 0.05
  bench: 0.3
args:
  block_size: ${model.args.block_size}
  cache_dir: #or path or empty string
  #specify how many samples a row contains. i.a. tiny_shakespeare fits its entire training data into one row, while rotten_tomatoes does not
  samples_per_row: singular #multiple
  save_token_file: True

defaults:
  - dataloader/default
  - tokenizer: transformers