{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc68ec43-3657-42a4-b936-c25a2410d9ac",
   "metadata": {},
   "source": [
    "## Train a GPT2 Transformer model with wikitext using BatchNorm/ LayerNorm and ReLU/ GELU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "811f5984-dd43-42fc-a60a-46115a11ef10",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mabot004/eki-transformer-dev/qtransform/eki/lib/python3.10/site-packages/qtransform-0.0.2.dev0-py3.10.egg/qtransform/conf\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from hydra import initialize, initialize_config_module, initialize_config_dir, compose\n",
    "from omegaconf import OmegaConf\n",
    "import qtransform\n",
    "import torch\n",
    "from brevitas import nn as qnn\n",
    "# Manually load some logging conf\n",
    "config_path = qtransform.get_module_config_path()\n",
    "print(config_path)\n",
    "import logging\n",
    "import yaml\n",
    "with open(os.path.join(config_path, 'hydra','job_logging', 'custom.yaml'), 'r') as stream:\n",
    "    config = yaml.load(stream, Loader=yaml.FullLoader)\n",
    "\n",
    "logging.config.dictConfig(config)\n",
    "logging.getLogger().setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bebfbb1-377b-45e3-ad42-29b32048a243",
   "metadata": {},
   "source": [
    "### Hyperparameters\n",
    "#### 10.000 Iterations in total with a small GPT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b43596d-18e0-4cfb-b467-d225d65b5aac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#from: https://github.com/karpathy/nanoGPT/blob/master/config/train_shakespeare_char.py and https://github.com/karpathy/nanoGPT/blob/master/config/train_gpt2.py\n",
    "#karpathy used a larger transformer model for openwebtext alongside more epochs\n",
    "\n",
    "DATASET = \"wikitext\"\n",
    "SUBSET = \"wikitext-103-raw-v1\"\n",
    "\n",
    "eval_epoch_interval = str(1) # every epoch, meaning after max_iters\n",
    "eval_iters = str(200)\n",
    "max_iters = str(500)\n",
    "epochs = \"20\" #eval after every epoch, karpathy has 5000 max_iters in total -> epoch = max_iters / eval_interval \n",
    "gradient_accumulation_steps = \"2\"\n",
    "batch_size = \"32\"\n",
    "block_size = \"256\"\n",
    "\n",
    "grad_clip=\"1.0\"\n",
    "\n",
    "n_layer = \"6\"\n",
    "n_head = \"6\"\n",
    "n_embd = \"384\"\n",
    "dropout = \"0.2\"\n",
    "\n",
    "learning_rate = str(1e-3) # with baby networks can afford to go a bit higher\n",
    "seed = \"1337\"\n",
    "\n",
    "step_size = epochs\n",
    "args = [\n",
    "    'seed='+seed,\n",
    "    'run=train',\n",
    "    'run.export=False',\n",
    "    'run.epochs='+epochs,\n",
    "    'run.max_iters='+max_iters,\n",
    "    'run.eval_epoch_interval='+eval_epoch_interval,\n",
    "    'run.eval_iters='+eval_iters,\n",
    "    'run.grad_clip='+grad_clip,\n",
    "    'run.gradient_accumulation_steps='+gradient_accumulation_steps,\n",
    "    'model.args.dropout='+dropout,\n",
    "    'model.args.n_layer='+n_layer,\n",
    "    'model.args.n_head='+n_head,\n",
    "    'model.args.n_embd='+n_embd,\n",
    "    'model.args.block_size='+n_embd,\n",
    "    'dataset=huggingface',\n",
    "    'dataset.name='+DATASET,\n",
    "    'dataset.subset='+SUBSET,\n",
    "    'dataset/tokenizer=tiktoken',\n",
    "    'dataset.tokenizer.encoding=gpt2',\n",
    "    'dataset.dataloader.shuffle=False',\n",
    "    'dataset.dataloader.batch_size='+batch_size,\n",
    "    'optim.args.learning_rate='+learning_rate,\n",
    "    'optim.scheduler.schedulers.1.args.step_size='+step_size,\n",
    "    'device=cuda',\n",
    "    'debug=True',\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6945b34-5419-412c-aaa8-3aaabc513f5d",
   "metadata": {},
   "source": [
    "#### ReLU BatchNorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c69105c8-72c2-4a4a-ae46-5f121eba03d3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data': {'dtype': 'float32'}, 'device': 'cuda', 'debug': True, 'dataset': {'wrapper': 'HuggingfaceDatasetWrapper', 'module': 'huggingface', 'name': 'wikitext', 'root_path': '~/.qtransform/datasets', 'dataset_dir': ['${dataset.root_path}', '${dataset.module}', '${dataset.name}'], 'sizes': {'train': 0.0, 'eval': 0.0, 'bench': 0.0}, 'tokenizer': {'dtype': '${data.dtype}', 'meta_file': 'meta.pkl', 'wrapper': 'TikTokenizer', 'encoding': 'gpt2', 'module': 'tiktoken'}, 'dataloader': {'shuffle': False, 'num_workers': 2, 'batch_size': 32}, 'subset': 'wikitext-103-raw-v1', 'type': 'huggingface', 'splits': {'names': {'train': 'train', 'eval': 'validation', 'bench': 'test'}, 'sizes': {'train': 0.9, 'eval': 0.05, 'bench': 0.05}}, 'args': {'block_size': '${model.args.block_size}', 'cache_dir': None, 'data_column_name': 'text', 'batches': 1000, 'chunking': True, 'chunk_size': 100}}, 'seed': 1337, 'model': {'calc_loss_in_model': True, 'cls': 'GPT', 'args': {'n_layer': 6, 'n_head': 6, 'n_embd': 384, 'dropout': 0.2, 'bias': True, 'block_size': 384, 'vocab_size': 50304, 'transformer_active_func': 'ReLU', 'norm_layer': 'BatchNorm', 'flash': False, 'single_output': False, 'use_weight_tying': True}}, 'quantization': {'quantize': False}, 'pipe': '/dev/null', 'optim': {'optimizer': 'AdamW', 'args': {'learning_rate': 0.001, 'weight_decay': 0.1, 'betas': [0.9, 0.95]}, 'scheduler': {'decay_lr': True, 'schedulers': {'1': {'name': 'StepLR', 'args': {'step_size': 20, 'gamma': 0.1}}}, 'milestones': None, 'warmup_epochs': 2}}, 'run': {'command': 'train', 'always_save_checkpoint': True, 'checkpoint_dir': 'models', 'from_checkpoint': None, 'epochs': 20, 'gradient_accumulation_steps': 2, 'flash': False, 'export': False, 'compile': True, 'max_iters': 500, 'save_epoch_interval': 1, 'log_steps_interval': 10, 'grad_clip': 1.0, 'eval_epoch_interval': 1, 'eval_iters': 200, 'profile': {'active': False, 'args': {'record_shapes': True, 'profile_memory': True, 'use_cuda': True}, 'row_limit': 10}}}\n",
      "[ \u001b[36m2024-03-06 09:55:10,020 \u001b[0m][\u001b[2;37mqtransform.qtransform.__main__\u001b[0m][\u001b[34mDEBUG\u001b[0m] - \u001b[34mDEBUG ENABLED\u001b[0m\n",
      "[ \u001b[36m2024-03-06 09:55:10,638 \u001b[0m][\u001b[2;37mnumexpr.utils\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32mNote: detected 128 virtual cores but NumExpr set to maximum of 64, check \"NUMEXPR_MAX_THREADS\" environment variable.\u001b[0m\n",
      "[ \u001b[36m2024-03-06 09:55:10,640 \u001b[0m][\u001b[2;37mnumexpr.utils\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32mNote: NumExpr detected 128 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\u001b[0m\n",
      "[ \u001b[36m2024-03-06 09:55:10,643 \u001b[0m][\u001b[2;37mnumexpr.utils\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32mNumExpr defaulting to 8 threads.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-06 09:55:11.258833: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ \u001b[36m2024-03-06 09:55:11,951 \u001b[0m][\u001b[2;37mtensorflow\u001b[0m][\u001b[34mDEBUG\u001b[0m] - \u001b[34mFalling back to TensorFlow client; we recommended you install the Cloud TPU client directly with pip install cloud-tpu-client.\u001b[0m\n",
      "[ \u001b[36m2024-03-06 09:55:12,051 \u001b[0m][\u001b[2;37mh5py._conv\u001b[0m][\u001b[34mDEBUG\u001b[0m] - \u001b[34mCreating converter from 7 to 5\u001b[0m\n",
      "[ \u001b[36m2024-03-06 09:55:12,054 \u001b[0m][\u001b[2;37mh5py._conv\u001b[0m][\u001b[34mDEBUG\u001b[0m] - \u001b[34mCreating converter from 5 to 7\u001b[0m\n",
      "[ \u001b[36m2024-03-06 09:55:12,056 \u001b[0m][\u001b[2;37mh5py._conv\u001b[0m][\u001b[34mDEBUG\u001b[0m] - \u001b[34mCreating converter from 7 to 5\u001b[0m\n",
      "[ \u001b[36m2024-03-06 09:55:12,059 \u001b[0m][\u001b[2;37mh5py._conv\u001b[0m][\u001b[34mDEBUG\u001b[0m] - \u001b[34mCreating converter from 5 to 7\u001b[0m\n",
      "[ \u001b[36m2024-03-06 09:55:12,671 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m================\u001b[0m\n",
      "[ \u001b[36m2024-03-06 09:55:12,674 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32mRunning Training\u001b[0m\n",
      "[ \u001b[36m2024-03-06 09:55:12,676 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m================\u001b[0m\n",
      "[ \u001b[36m2024-03-06 09:55:12,678 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32mtime is: 2024-03-06_09:55:12\u001b[0m\n",
      "[ \u001b[36m2024-03-06 09:55:12,681 \u001b[0m][\u001b[2;37mqtransform\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32mDevice specified: cuda. Using device: cuda\u001b[0m\n",
      "[ \u001b[36m2024-03-06 09:55:12,687 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32mnumber of torch dataloader: 2\u001b[0m\n",
      "[ \u001b[36m2024-03-06 09:55:12,689 \u001b[0m][\u001b[2;37mqtransform.dataset\u001b[0m][\u001b[34mDEBUG\u001b[0m] - \u001b[34mLoading class qtransform.dataset.HuggingfaceDatasetWrapper(parent: <class 'qtransform.dataset.DatasetWrapper'>)\u001b[0m\n",
      "[ \u001b[36m2024-03-06 09:55:12,771 \u001b[0m][\u001b[2;37mqtransform.dataset\u001b[0m][\u001b[34mDEBUG\u001b[0m] - \u001b[34mPassing arguments {'cfg': {'wrapper': 'HuggingfaceDatasetWrapper', 'module': 'huggingface', 'name': 'wikitext', 'root_path': '~/.qtransform/datasets', 'dataset_dir': ['${dataset.root_path}', '${dataset.module}', '${dataset.name}'], 'sizes': {'train': 0.0, 'eval': 0.0, 'bench': 0.0}, 'tokenizer': {'dtype': '${data.dtype}', 'meta_file': 'meta.pkl', 'wrapper': 'TikTokenizer', 'encoding': 'gpt2', 'module': 'tiktoken'}, 'dataloader': {'shuffle': False, 'num_workers': 2, 'batch_size': 32, 'pin_memory': True}, 'subset': 'wikitext-103-raw-v1', 'type': 'huggingface', 'splits': {'names': {'train': 'train', 'eval': 'validation', 'bench': 'test'}, 'sizes': {'train': 0.9, 'eval': 0.05, 'bench': 0.05}}, 'args': {'block_size': '${model.args.block_size}', 'cache_dir': None, 'data_column_name': 'text', 'batches': 1000, 'chunking': True, 'chunk_size': 100}}} to class: <class 'qtransform.dataset.huggingface.HuggingfaceDatasetWrapper'>\u001b[0m\n",
      "[ \u001b[36m2024-03-06 09:55:12,778 \u001b[0m][\u001b[2;37mqtransform.dataset.tokenizer\u001b[0m][\u001b[34mDEBUG\u001b[0m] - \u001b[34mAttempting to retrieve tokenizer with cfg: {'dtype': '${data.dtype}', 'meta_file': 'meta.pkl', 'wrapper': 'TikTokenizer', 'encoding': 'gpt2', 'module': 'tiktoken'}\u001b[0m\n",
      "[ \u001b[36m2024-03-06 09:55:12,780 \u001b[0m][\u001b[2;37mqtransform.dataset.tokenizer\u001b[0m][\u001b[34mDEBUG\u001b[0m] - \u001b[34mLoading class qtransform.dataset.tokenizer.TikTokenizer(parent: <class 'qtransform.dataset.tokenizer.tokenizer.Tokenizer'>)\u001b[0m\n",
      "[ \u001b[36m2024-03-06 09:55:12,785 \u001b[0m][\u001b[2;37mqtransform.dataset.tokenizer\u001b[0m][\u001b[34mDEBUG\u001b[0m] - \u001b[34mPassing arguments {'tokenizer_cfg': {'dtype': '${data.dtype}', 'meta_file': 'meta.pkl', 'wrapper': 'TikTokenizer', 'encoding': 'gpt2', 'module': 'tiktoken'}, 'memmap': None} to class: <class 'qtransform.dataset.tokenizer.tiktoken.TikTokenizer'>\u001b[0m\n",
      "[ \u001b[36m2024-03-06 09:55:12,787 \u001b[0m][\u001b[2;37mqtransform.dataset.tokenizer.tokenizer\u001b[0m][\u001b[34mDEBUG\u001b[0m] - \u001b[34mCreating Tokenizer with parameters: {'dtype': '${data.dtype}', 'meta_file': 'meta.pkl', 'wrapper': 'TikTokenizer', 'encoding': 'gpt2', 'module': 'tiktoken'}\u001b[0m\n",
      "[ \u001b[36m2024-03-06 09:55:12,998 \u001b[0m][\u001b[2;37mqtransform.dataset\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32mLoading dataset: wikitext, with encoding: gpt2 and dtype: float32\u001b[0m\n",
      "[ \u001b[36m2024-03-06 09:55:13,004 \u001b[0m][\u001b[2;37mqtransform.dataset\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32mAttempting to retrieve tokenized dataset under \"/home/mabot004/.qtransform/datasets/huggingface/wikitext/tokenized/gpt2/train-wikitext-103-raw-v1-float32.bin\"\u001b[0m\n",
      "[ \u001b[36m2024-03-06 09:55:13,007 \u001b[0m][\u001b[2;37mqtransform.dataset\u001b[0m][\u001b[34mDEBUG\u001b[0m] - \u001b[34mOffset is 0, start is 0.0, end is 1.0\u001b[0m\n",
      "[ \u001b[36m2024-03-06 09:55:13,009 \u001b[0m][\u001b[2;37mqtransform.dataset\u001b[0m][\u001b[34mDEBUG\u001b[0m] - \u001b[34mTokenized file has 123368382.0 tokens of datatype: float32. Attempting to start at token: 0\u001b[0m\n",
      "[ \u001b[36m2024-03-06 09:55:13,012 \u001b[0m][\u001b[2;37mqtransform.dataset\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32mLoaded data has 123368382 tokens.\u001b[0m\n",
      "[ \u001b[36m2024-03-06 09:55:13,015 \u001b[0m][\u001b[2;37mqtransform.dataset\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32mAttempting to retrieve tokenized dataset under \"/home/mabot004/.qtransform/datasets/huggingface/wikitext/tokenized/gpt2/eval-wikitext-103-raw-v1-float32.bin\"\u001b[0m\n",
      "[ \u001b[36m2024-03-06 09:55:13,018 \u001b[0m][\u001b[2;37mqtransform.dataset\u001b[0m][\u001b[34mDEBUG\u001b[0m] - \u001b[34mOffset is 0, start is 0.0, end is 1.0\u001b[0m\n",
      "[ \u001b[36m2024-03-06 09:55:13,020 \u001b[0m][\u001b[2;37mqtransform.dataset\u001b[0m][\u001b[34mDEBUG\u001b[0m] - \u001b[34mTokenized file has 258896.0 tokens of datatype: float32. Attempting to start at token: 0\u001b[0m\n",
      "[ \u001b[36m2024-03-06 09:55:13,023 \u001b[0m][\u001b[2;37mqtransform.dataset\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32mLoaded data has 258896 tokens.\u001b[0m\n",
      "[ \u001b[36m2024-03-06 09:55:13,026 \u001b[0m][\u001b[2;37mqtransform.dataset\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32mAttempting to retrieve tokenized dataset under \"/home/mabot004/.qtransform/datasets/huggingface/wikitext/tokenized/gpt2/bench-wikitext-103-raw-v1-float32.bin\"\u001b[0m\n",
      "[ \u001b[36m2024-03-06 09:55:13,028 \u001b[0m][\u001b[2;37mqtransform.dataset\u001b[0m][\u001b[34mDEBUG\u001b[0m] - \u001b[34mOffset is 0, start is 0.0, end is 1.0\u001b[0m\n",
      "[ \u001b[36m2024-03-06 09:55:13,030 \u001b[0m][\u001b[2;37mqtransform.dataset\u001b[0m][\u001b[34mDEBUG\u001b[0m] - \u001b[34mTokenized file has 296271.0 tokens of datatype: float32. Attempting to start at token: 0\u001b[0m\n",
      "[ \u001b[36m2024-03-06 09:55:13,032 \u001b[0m][\u001b[2;37mqtransform.dataset\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32mLoaded data has 296271 tokens.\u001b[0m\n",
      "[ \u001b[36m2024-03-06 09:55:13,036 \u001b[0m][\u001b[2;37mqtransform.dataset\u001b[0m][\u001b[34mDEBUG\u001b[0m] - \u001b[34mget_loader config: {'shuffle': False, 'num_workers': 2, 'batch_size': 32, 'pin_memory': True}\u001b[0m\n",
      "[ \u001b[36m2024-03-06 09:55:13,039 \u001b[0m][\u001b[2;37mqtransform.dataset\u001b[0m][\u001b[34mDEBUG\u001b[0m] - \u001b[34mlen: 3855262\u001b[0m\n",
      "[ \u001b[36m2024-03-06 09:55:13,042 \u001b[0m][\u001b[2;37mqtransform.dataset\u001b[0m][\u001b[34mDEBUG\u001b[0m] - \u001b[34mget_loader config: {'shuffle': False, 'num_workers': 2, 'batch_size': 32, 'pin_memory': True}\u001b[0m\n",
      "[ \u001b[36m2024-03-06 09:55:13,045 \u001b[0m][\u001b[2;37mqtransform.dataset\u001b[0m][\u001b[34mDEBUG\u001b[0m] - \u001b[34mlen: 8091\u001b[0m\n",
      "[ \u001b[36m2024-03-06 09:55:13,050 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[33mWARNING\u001b[0m] - \u001b[33mVocab size of model is larger than the tokenizer vocab. Setting vocab_size to: 50256 to prevent errors during inference\u001b[0m\n",
      "[ \u001b[36m2024-03-06 09:55:13,055 \u001b[0m][\u001b[2;37mqtransform.model\u001b[0m][\u001b[34mDEBUG\u001b[0m] - \u001b[34mget_model config: {'calc_loss_in_model': True, 'cls': 'GPT', 'args': {'n_layer': 6, 'n_head': 6, 'n_embd': 384, 'dropout': 0.2, 'bias': True, 'block_size': 384, 'vocab_size': 50256, 'transformer_active_func': 'ReLU', 'norm_layer': 'BatchNorm', 'flash': False, 'single_output': False, 'use_weight_tying': True}}\u001b[0m\n",
      "[ \u001b[36m2024-03-06 09:55:13,057 \u001b[0m][\u001b[2;37mqtransform.model\u001b[0m][\u001b[34mDEBUG\u001b[0m] - \u001b[34mLoading class qtransform.model.GPT(parent: <class 'torch.nn.modules.module.Module'>)\u001b[0m\n",
      "[ \u001b[36m2024-03-06 09:55:13,087 \u001b[0m][\u001b[2;37mqtransform.model.gpt\u001b[0m][\u001b[34mDEBUG\u001b[0m] - \u001b[34mApplied config: \n",
      "GPTConfig(block_size=384, vocab_size=50256, n_layer=6, n_head=6, n_embd=384, dropout=0.2, bias=True, flash=False, transformer_active_func='ReLU', norm_layer='BatchNorm', single_output=False, use_weight_tying=True, custom_ln=False)\u001b[0m\n",
      "[ \u001b[36m2024-03-06 09:55:13,090 \u001b[0m][\u001b[2;37mqtransform.model.gpt\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32mModel config: GPTConfig(block_size=384, vocab_size=50256, n_layer=6, n_head=6, n_embd=384, dropout=0.2, bias=True, flash=False, transformer_active_func='ReLU', norm_layer='BatchNorm', single_output=False, use_weight_tying=True, custom_ln=False)\u001b[0m\n",
      "50256 384\n",
      "[ \u001b[36m2024-03-06 09:55:13,249 \u001b[0m][\u001b[2;37mqtransform.model.modules\u001b[0m][\u001b[33mWARNING\u001b[0m] - \u001b[33mWARNING: using slow attention. Flash Attention requires PyTorch >= 2.2\u001b[0m\n",
      "[ \u001b[36m2024-03-06 09:55:13,260 \u001b[0m][\u001b[2;37mqtransform.model.modules\u001b[0m][\u001b[33mWARNING\u001b[0m] - \u001b[33mWARNING: using slow attention. Flash Attention requires PyTorch >= 2.2\u001b[0m\n",
      "[ \u001b[36m2024-03-06 09:55:13,294 \u001b[0m][\u001b[2;37mqtransform.model.modules\u001b[0m][\u001b[33mWARNING\u001b[0m] - \u001b[33mWARNING: using slow attention. Flash Attention requires PyTorch >= 2.2\u001b[0m\n",
      "[ \u001b[36m2024-03-06 09:55:13,306 \u001b[0m][\u001b[2;37mqtransform.model.modules\u001b[0m][\u001b[33mWARNING\u001b[0m] - \u001b[33mWARNING: using slow attention. Flash Attention requires PyTorch >= 2.2\u001b[0m\n",
      "[ \u001b[36m2024-03-06 09:55:13,331 \u001b[0m][\u001b[2;37mqtransform.model.modules\u001b[0m][\u001b[33mWARNING\u001b[0m] - \u001b[33mWARNING: using slow attention. Flash Attention requires PyTorch >= 2.2\u001b[0m\n",
      "[ \u001b[36m2024-03-06 09:55:13,394 \u001b[0m][\u001b[2;37mqtransform.model.modules\u001b[0m][\u001b[33mWARNING\u001b[0m] - \u001b[33mWARNING: using slow attention. Flash Attention requires PyTorch >= 2.2\u001b[0m\n",
      "[ \u001b[36m2024-03-06 09:55:13,412 \u001b[0m][\u001b[2;37mqtransform.model.modules\u001b[0m][\u001b[33mWARNING\u001b[0m] - \u001b[33mWARNING: using slow attention. Flash Attention requires PyTorch >= 2.2\u001b[0m\n",
      "[ \u001b[36m2024-03-06 09:55:13,483 \u001b[0m][\u001b[2;37mqtransform.model.modules\u001b[0m][\u001b[33mWARNING\u001b[0m] - \u001b[33mWARNING: using slow attention. Flash Attention requires PyTorch >= 2.2\u001b[0m\n",
      "[ \u001b[36m2024-03-06 09:55:13,504 \u001b[0m][\u001b[2;37mqtransform.model.modules\u001b[0m][\u001b[33mWARNING\u001b[0m] - \u001b[33mWARNING: using slow attention. Flash Attention requires PyTorch >= 2.2\u001b[0m\n",
      "[ \u001b[36m2024-03-06 09:55:13,520 \u001b[0m][\u001b[2;37mqtransform.model.modules\u001b[0m][\u001b[33mWARNING\u001b[0m] - \u001b[33mWARNING: using slow attention. Flash Attention requires PyTorch >= 2.2\u001b[0m\n",
      "[ \u001b[36m2024-03-06 09:55:13,589 \u001b[0m][\u001b[2;37mqtransform.model.modules\u001b[0m][\u001b[33mWARNING\u001b[0m] - \u001b[33mWARNING: using slow attention. Flash Attention requires PyTorch >= 2.2\u001b[0m\n",
      "[ \u001b[36m2024-03-06 09:55:13,605 \u001b[0m][\u001b[2;37mqtransform.model.modules\u001b[0m][\u001b[33mWARNING\u001b[0m] - \u001b[33mWARNING: using slow attention. Flash Attention requires PyTorch >= 2.2\u001b[0m\n",
      "[ \u001b[36m2024-03-06 09:55:14,014 \u001b[0m][\u001b[2;37mqtransform.model.gpt\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32mnumber of parameters: 52.79M\u001b[0m\n",
      "[ \u001b[36m2024-03-06 09:55:15,853 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[34mDEBUG\u001b[0m] - \u001b[34moptim config: {'optimizer': 'AdamW', 'args': {'learning_rate': 0.001, 'weight_decay': 0.1, 'betas': [0.9, 0.95]}, 'scheduler': {'decay_lr': True, 'schedulers': {'1': {'name': 'StepLR', 'args': {'step_size': 20, 'gamma': 0.1}}}, 'milestones': None, 'warmup_epochs': 2}}\u001b[0m\n",
      "[ \u001b[36m2024-03-06 09:55:15,857 \u001b[0m][\u001b[2;37mqtransform.optim\u001b[0m][\u001b[34mDEBUG\u001b[0m] - \u001b[34mLoading class torch.optim.AdamW(parent: <class 'torch.optim.optimizer.Optimizer'>)\u001b[0m\n",
      "[ \u001b[36m2024-03-06 09:55:15,861 \u001b[0m][\u001b[2;37mqtransform.optim\u001b[0m][\u001b[34mDEBUG\u001b[0m] - \u001b[34mConfigurable optimizer args: {'lr', 'weight_decay', 'betas'}\u001b[0m\n",
      "[ \u001b[36m2024-03-06 09:55:15,864 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[34mDEBUG\u001b[0m] - \u001b[34mConfigured optimizer (<class 'torch.optim._multi_tensor.partialclass.<locals>.NewCls'>): NewCls (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: [0.9, 0.95]\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: True\n",
      "    fused: None\n",
      "    lr: 0.001\n",
      "    maximize: False\n",
      "    weight_decay: 0.1\n",
      ")\u001b[0m\n",
      "[ \u001b[36m2024-03-06 09:55:15,866 \u001b[0m][\u001b[2;37mqtransform.optim.scheduler\u001b[0m][\u001b[34mDEBUG\u001b[0m] - \u001b[34mGetting scheduler\u001b[0m\n",
      "[ \u001b[36m2024-03-06 09:55:15,868 \u001b[0m][\u001b[2;37mqtransform.optim.scheduler\u001b[0m][\u001b[34mDEBUG\u001b[0m] - \u001b[34mGoing through scheduler: StepLR with args: {'step_size': 20, 'gamma': 0.1}\u001b[0m\n",
      "[ \u001b[36m2024-03-06 09:55:15,870 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[34mDEBUG\u001b[0m] - \u001b[34mScheduler: <torch.optim.lr_scheduler.SequentialLR object at 0x7f0bf062b4c0>\u001b[0m\n",
      "[ \u001b[36m2024-03-06 09:55:15,872 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32mStarting new training\u001b[0m\n",
      "[ \u001b[36m2024-03-06 09:55:15,875 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32mEPOCH: 1/20\u001b[0m\n",
      "[ \u001b[36m2024-03-06 09:55:31,498 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 10 loss: 4.468165111541748. time: 15505.37ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 09:55:46,236 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 20 loss: 3.863453769683838. time: 14732.88ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 09:56:01,085 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 30 loss: 3.830840015411377. time: 14845.37ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 09:56:16,102 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 40 loss: 3.8035224199295046. time: 15013.67ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 09:56:31,027 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 50 loss: 3.5879533767700194. time: 14921.92ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 09:56:45,917 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 60 loss: 3.6559708595275877. time: 14886.72ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 09:57:00,872 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 70 loss: 3.763181281089783. time: 14951.80ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 09:57:15,974 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 80 loss: 3.7160590648651124. time: 15098.11ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 09:57:30,753 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 90 loss: 3.6256284952163695. time: 14776.51ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 09:57:45,763 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 100 loss: 3.6002506971359254. time: 15005.84ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 09:58:00,819 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 110 loss: 3.629216432571411. time: 15053.16ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 09:58:15,972 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 120 loss: 3.5290179014205934. time: 15148.99ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 09:58:31,044 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 130 loss: 3.4754909753799437. time: 15069.38ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 09:58:45,762 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 140 loss: 3.5891658067703247. time: 14711.42ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 09:59:00,478 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 150 loss: 3.5792851209640504. time: 14712.61ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 09:59:15,217 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 160 loss: 3.5656336545944214. time: 14735.75ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 09:59:30,217 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 170 loss: 3.500715970993042. time: 14997.22ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 09:59:45,241 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 180 loss: 3.5435913801193237. time: 15020.63ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:00:00,208 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 190 loss: 3.4596085071563722. time: 14963.78ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:00:15,510 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 200 loss: 3.497603416442871. time: 15299.08ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:00:30,492 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 210 loss: 3.4297690868377684. time: 14977.74ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:00:45,623 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 220 loss: 3.494957971572876. time: 15126.88ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:01:00,550 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 230 loss: 3.431210422515869. time: 14921.43ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:01:15,497 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 240 loss: 3.5855536699295043. time: 14942.30ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:01:30,258 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 250 loss: 3.442506217956543. time: 14758.29ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:01:45,092 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 260 loss: 3.5311264276504515. time: 14830.69ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:02:00,173 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 270 loss: 3.463163137435913. time: 15076.77ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:02:15,062 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 280 loss: 3.3635823726654053. time: 14885.30ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:02:30,061 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 290 loss: 3.4243727684020997. time: 14993.97ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:02:44,948 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 300 loss: 3.3956406831741335. time: 14884.29ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:02:59,791 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 310 loss: 3.4950610876083372. time: 14839.24ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:03:14,865 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 320 loss: 3.4236650705337524. time: 15070.58ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:03:29,545 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 330 loss: 3.4853399753570558. time: 14676.45ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:03:44,177 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 340 loss: 3.4281230688095095. time: 14627.38ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:03:58,918 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 350 loss: 3.406563067436218. time: 14737.94ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:04:13,664 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 360 loss: 3.552060294151306. time: 14742.88ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:04:28,568 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 370 loss: 3.4294751405715944. time: 14900.83ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:04:43,473 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 380 loss: 3.478749394416809. time: 14899.95ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:04:58,440 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 390 loss: 3.5630224466323854. time: 14964.54ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:05:13,411 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 400 loss: 3.557004189491272. time: 14967.44ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:05:28,065 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 410 loss: 3.404307723045349. time: 14650.81ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:05:43,016 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 420 loss: 3.547821855545044. time: 14946.93ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:05:58,023 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 430 loss: 3.4535225868225097. time: 15004.13ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:06:12,902 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 440 loss: 3.5229932069778442. time: 14875.86ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:06:27,697 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 450 loss: 3.4409313678741453. time: 14791.11ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:06:42,506 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 460 loss: 3.4526741027832033. time: 14804.79ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:06:57,344 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 470 loss: 3.4957727193832397. time: 14834.77ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:07:11,983 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 480 loss: 3.480402874946594. time: 14634.76ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:07:26,776 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 490 loss: 3.4196393966674803. time: 14788.82ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:07:41,382 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 500 loss: 3.4932264566421507. time: 14602.90ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:08:09,012 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32mAVERAGE EVAL LOSS FOR EPOCH 1/20: 7.695990085601807\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:08:09,016 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m3.4932264566421507\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:08:09,994 \u001b[0m][\u001b[2;37mqtransform.utils.helper\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32mModel checkpoint saved to /home/mabot004/eki-transformer-dev/shakespeare_owt_benchmarking/wikitext/GPT_wikitext_2024-03-06_09:55:12__epoch:1\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:08:09,996 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[34mDEBUG\u001b[0m] - \u001b[34mNew learning rate: 0.001\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:08:09,998 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32mEPOCH: 2/20\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:08:25,039 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 10 loss: 2.7607351779937743. time: 14929.78ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:08:39,901 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 20 loss: 2.47693874835968. time: 14858.28ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:08:54,997 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 30 loss: 2.3836052656173705. time: 15092.15ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:09:09,836 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 40 loss: 2.3831386804580688. time: 14836.23ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:09:24,878 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 50 loss: 2.273767614364624. time: 15038.39ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:09:39,770 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 60 loss: 2.381374979019165. time: 14889.28ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:09:54,678 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 70 loss: 2.378515195846558. time: 14903.90ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:10:09,586 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 80 loss: 2.355606722831726. time: 14904.81ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:10:24,353 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 90 loss: 2.355942440032959. time: 14764.14ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:10:39,254 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 100 loss: 2.2604315280914307. time: 14897.14ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:10:54,224 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 110 loss: 2.185665488243103. time: 14966.77ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:11:08,971 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 120 loss: 2.137936305999756. time: 14743.60ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:11:23,714 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 130 loss: 2.088527798652649. time: 14739.02ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:11:38,747 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 140 loss: 2.191818046569824. time: 15029.99ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:11:53,541 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 150 loss: 2.124327778816223. time: 14790.46ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:12:08,296 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 160 loss: 2.1107636213302614. time: 14751.31ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:12:23,418 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 170 loss: 2.052748703956604. time: 15118.56ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:12:38,289 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 180 loss: 2.0740344524383545. time: 14867.67ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:12:53,298 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 190 loss: 2.0538177728652953. time: 15005.42ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:13:08,280 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 200 loss: 2.101434278488159. time: 14978.96ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:13:23,240 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 210 loss: 1.9951220989227294. time: 14956.78ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:13:38,061 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 220 loss: 2.0892041325569153. time: 14817.78ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:13:53,062 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 230 loss: 2.08955397605896. time: 14998.23ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:14:08,164 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 240 loss: 2.0752198696136475. time: 15098.78ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:14:22,882 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 250 loss: 2.081634020805359. time: 14714.19ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:14:37,892 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 260 loss: 2.04259797334671. time: 15007.11ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:14:52,784 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 270 loss: 2.0020549654960633. time: 14887.47ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:15:07,637 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 280 loss: 2.0238621115684508. time: 14849.76ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:15:22,420 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 290 loss: 2.0366924166679383. time: 14779.39ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:15:36,861 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 300 loss: 2.0059183120727537. time: 14438.09ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:15:51,830 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 310 loss: 2.1307583808898927. time: 14965.59ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:16:06,583 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 320 loss: 2.0313583493232725. time: 14749.78ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:16:21,303 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 330 loss: 2.128831624984741. time: 14716.34ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:16:36,091 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 340 loss: 2.0411325097084045. time: 14784.03ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:16:51,007 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 350 loss: 2.035211372375488. time: 14911.99ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:17:05,869 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 360 loss: 2.152188754081726. time: 14859.90ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:17:20,814 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 370 loss: 1.9828347563743591. time: 14941.38ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:17:35,620 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 380 loss: 2.0000808954238893. time: 14801.96ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:17:50,544 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 390 loss: 2.120115780830383. time: 14921.07ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:18:05,264 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 400 loss: 2.032549023628235. time: 14716.65ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:18:20,136 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 410 loss: 2.062616288661957. time: 14869.53ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:18:34,899 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 420 loss: 2.115959084033966. time: 14760.00ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:18:49,540 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 430 loss: 2.0298868060112. time: 14637.31ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:19:04,313 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 440 loss: 2.1392408847808837. time: 14770.00ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:19:19,024 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 450 loss: 1.9599002838134765. time: 14708.34ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:19:34,048 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 460 loss: 2.1184298515319826. time: 15019.87ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:19:49,033 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 470 loss: 2.071940779685974. time: 14981.20ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:20:03,766 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 480 loss: 1.9460633516311645. time: 14729.34ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:20:18,603 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 490 loss: 2.020484173297882. time: 14833.47ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:20:33,412 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 500 loss: 2.07806111574173. time: 14805.55ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:21:01,056 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32mAVERAGE EVAL LOSS FOR EPOCH 2/20: 8.780110359191895\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:21:01,061 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m2.07806111574173\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:21:02,012 \u001b[0m][\u001b[2;37mqtransform.utils.helper\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32mModel checkpoint saved to /home/mabot004/eki-transformer-dev/shakespeare_owt_benchmarking/wikitext/GPT_wikitext_2024-03-06_09:55:12__epoch:2\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:21:02,014 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[34mDEBUG\u001b[0m] - \u001b[34mNew learning rate: 0.001\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:21:02,016 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32mEPOCH: 3/20\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:21:17,031 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 10 loss: 2.0654695868492126. time: 14903.00ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:21:32,086 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 20 loss: 1.6194804549217223. time: 15050.51ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:21:46,716 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 30 loss: 1.8725627183914184. time: 14626.56ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:22:01,329 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 40 loss: 1.6328127145767213. time: 14609.55ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:22:15,742 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 50 loss: 1.7065049767494203. time: 14410.67ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:22:30,573 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 60 loss: 1.798755371570587. time: 14828.03ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:22:45,275 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 70 loss: 1.8394399762153626. time: 14699.55ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:23:00,114 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 80 loss: 1.8237080335617066. time: 14835.25ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:23:15,165 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 90 loss: 1.6832813382148744. time: 15047.79ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:23:29,936 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 100 loss: 1.6782077074050903. time: 14769.22ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:23:44,926 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 110 loss: 1.6483022451400757. time: 14987.74ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:23:59,763 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 120 loss: 1.6320488095283507. time: 14832.75ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:24:14,664 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 130 loss: 1.5901662111282349. time: 14897.70ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:24:29,821 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 140 loss: 1.6191968679428101. time: 15154.30ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:24:44,523 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 150 loss: 1.571455991268158. time: 14698.50ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:24:59,549 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 160 loss: 1.5696088075637817. time: 15021.85ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:25:14,380 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 170 loss: 1.5450523018836975. time: 14826.50ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:25:29,109 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 180 loss: 1.5970615029335022. time: 14726.05ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:25:43,973 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 190 loss: 1.554919958114624. time: 14860.56ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:25:58,897 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 200 loss: 1.6568568706512452. time: 14919.90ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:26:13,891 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 210 loss: 1.5621008038520814. time: 14990.06ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:26:28,885 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 220 loss: 1.6619160056114197. time: 14990.23ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:26:43,788 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 230 loss: 1.6274087309837342. time: 14899.85ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:26:58,585 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 240 loss: 1.5218254804611206. time: 14793.03ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:27:13,572 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 250 loss: 1.606076729297638. time: 14983.89ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:27:28,415 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 260 loss: 1.708380937576294. time: 14839.11ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:27:43,147 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 270 loss: 1.5459920763969421. time: 14726.66ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:27:57,951 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 280 loss: 1.6384593486785888. time: 14800.70ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:28:12,920 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 290 loss: 1.5482717871665954. time: 14964.62ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:28:27,501 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 300 loss: 1.5382656693458556. time: 14577.93ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:28:42,368 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 310 loss: 1.599350380897522. time: 14863.58ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:28:57,248 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 320 loss: 1.6217812776565552. time: 14877.38ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:29:12,256 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 330 loss: 1.6445584774017334. time: 15003.34ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:29:27,065 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 340 loss: 1.581539261341095. time: 14805.33ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:29:41,952 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 350 loss: 1.5823363423347474. time: 14883.49ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:29:56,839 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 360 loss: 1.6649068593978882. time: 14883.92ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:30:11,629 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 370 loss: 1.469261884689331. time: 14786.27ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:30:26,521 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 380 loss: 1.556854283809662. time: 14889.26ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:30:41,469 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 390 loss: 1.5390666604042054. time: 14945.14ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:30:56,143 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 400 loss: 1.5171589136123658. time: 14671.95ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:31:10,971 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 410 loss: 1.7028992772102356. time: 14824.80ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:31:25,751 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 420 loss: 1.6067750453948975. time: 14778.05ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:31:40,678 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 430 loss: 1.5241446375846863. time: 14923.04ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:31:55,703 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 440 loss: 1.6225306510925293. time: 15022.19ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:32:10,678 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 450 loss: 1.5087277054786683. time: 14971.38ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:32:25,431 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 460 loss: 1.60467848777771. time: 14748.28ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:32:40,158 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 470 loss: 1.5269946098327636. time: 14723.14ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:32:55,136 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 480 loss: 1.4623137354850768. time: 14974.74ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:33:10,268 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 490 loss: 1.5040450692176819. time: 15129.03ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:33:25,347 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 500 loss: 1.7636801481246949. time: 15075.55ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:33:53,010 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32mAVERAGE EVAL LOSS FOR EPOCH 3/20: 9.705998420715332\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:33:53,013 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m1.7636801481246949\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:33:53,988 \u001b[0m][\u001b[2;37mqtransform.utils.helper\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32mModel checkpoint saved to /home/mabot004/eki-transformer-dev/shakespeare_owt_benchmarking/wikitext/GPT_wikitext_2024-03-06_09:55:12__epoch:3\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:33:53,991 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[34mDEBUG\u001b[0m] - \u001b[34mNew learning rate: 0.001\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:33:53,992 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32mEPOCH: 4/20\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:34:09,402 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 10 loss: 1.730395221710205. time: 15294.59ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:34:24,439 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 20 loss: 1.3335394024848939. time: 15032.01ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:34:39,069 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 30 loss: 1.5057497024536133. time: 14626.62ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:34:53,745 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 40 loss: 1.401426649093628. time: 14672.48ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:35:08,364 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 50 loss: 1.5207301020622253. time: 14615.64ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:35:23,141 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 60 loss: 1.5408972382545472. time: 14773.55ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:35:37,998 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 70 loss: 1.50232595205307. time: 14853.87ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:35:53,018 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 80 loss: 1.5239320158958436. time: 15016.13ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:36:07,757 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 90 loss: 1.4759392619132996. time: 14736.17ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:36:22,712 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 100 loss: 1.4217732667922973. time: 14950.75ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:36:37,803 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 110 loss: 1.392762541770935. time: 15087.37ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:36:52,832 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 120 loss: 1.411553728580475. time: 15024.76ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:37:07,666 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 130 loss: 1.3950782656669616. time: 14830.17ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:37:22,533 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 140 loss: 1.4841063499450684. time: 14863.67ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:37:37,559 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 150 loss: 1.4644413590431213. time: 15022.56ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:37:52,298 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 160 loss: 1.354837715625763. time: 14734.32ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:38:07,015 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 170 loss: 1.3485646367073059. time: 14715.24ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:38:21,942 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 180 loss: 1.4714184641838073. time: 14923.97ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:38:36,823 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 190 loss: 1.4544399499893188. time: 14878.37ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:38:51,462 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 200 loss: 1.4325482964515686. time: 14635.57ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:39:06,269 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 210 loss: 1.3823813199996948. time: 14803.76ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:39:21,249 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 220 loss: 1.4847838878631592. time: 14976.63ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:39:36,388 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 230 loss: 1.5033463716506958. time: 15135.56ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:39:51,358 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 240 loss: 1.3581288695335387. time: 14966.69ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:40:06,252 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 250 loss: 1.509542465209961. time: 14890.86ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:40:21,287 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 260 loss: 1.5092078924179078. time: 15031.10ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:40:36,232 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 270 loss: 1.3326135158538819. time: 14941.45ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:40:51,036 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 280 loss: 1.466839063167572. time: 14800.19ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:41:06,013 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 290 loss: 1.4613152503967286. time: 14974.07ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:41:20,825 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 300 loss: 1.4601749300956726. time: 14807.62ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:41:35,551 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 310 loss: 1.4343706250190735. time: 14722.07ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:41:50,685 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 320 loss: 1.434687614440918. time: 15129.21ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:42:05,712 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 330 loss: 1.491834247112274. time: 15024.47ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:42:20,648 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 340 loss: 1.4538264513015746. time: 14933.10ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:42:35,405 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 350 loss: 1.4179799199104308. time: 14752.72ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:42:50,430 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 360 loss: 1.4919662714004516. time: 15021.99ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:43:05,247 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 370 loss: 1.4192650198936463. time: 14812.28ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:43:19,933 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 380 loss: 1.467881679534912. time: 14682.72ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:43:34,736 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 390 loss: 1.4224027872085572. time: 14798.82ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:43:49,656 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 400 loss: 1.428830099105835. time: 14916.61ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:44:04,589 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 410 loss: 1.4749578833580017. time: 14928.01ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:44:19,423 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 420 loss: 1.5601048588752746. time: 14831.46ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:44:34,362 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 430 loss: 1.3876871109008788. time: 14935.00ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:44:49,082 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 440 loss: 1.4413756489753724. time: 14717.27ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:45:03,882 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 450 loss: 1.4293295383453368. time: 14795.75ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:45:18,671 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 460 loss: 1.3971605896949768. time: 14785.36ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:45:33,676 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 470 loss: 1.4060040593147278. time: 15002.01ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:45:48,478 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 480 loss: 1.3271718978881837. time: 14798.48ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:46:03,370 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 490 loss: 1.4897098422050477. time: 14888.27ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:46:18,245 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 500 loss: 1.5984533071517943. time: 14870.77ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:46:45,977 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32mAVERAGE EVAL LOSS FOR EPOCH 4/20: 9.604772567749023\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:46:45,981 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m1.5984533071517943\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:46:46,914 \u001b[0m][\u001b[2;37mqtransform.utils.helper\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32mModel checkpoint saved to /home/mabot004/eki-transformer-dev/shakespeare_owt_benchmarking/wikitext/GPT_wikitext_2024-03-06_09:55:12__epoch:4\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:46:46,916 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[34mDEBUG\u001b[0m] - \u001b[34mNew learning rate: 0.001\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:46:46,918 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32mEPOCH: 5/20\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:47:01,941 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 10 loss: 1.629147970676422. time: 14915.50ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:47:16,812 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 20 loss: 1.340042519569397. time: 14866.49ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:47:31,694 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 30 loss: 1.4146939635276794. time: 14880.54ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:47:46,698 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 40 loss: 1.4008098125457764. time: 15000.92ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:48:01,508 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 50 loss: 1.4775816202163696. time: 14807.30ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:48:16,336 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 60 loss: 1.527278220653534. time: 14824.78ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:48:31,357 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 70 loss: 1.4136868596076966. time: 15017.37ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:48:46,540 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 80 loss: 1.4060712099075316. time: 15180.87ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:49:01,563 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 90 loss: 1.3341290354728699. time: 15019.55ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:49:16,322 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 100 loss: 1.3220038414001465. time: 14755.98ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:49:31,208 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 110 loss: 1.2697092652320863. time: 14882.15ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:49:45,962 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 120 loss: 1.3313217878341674. time: 14751.12ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:50:00,716 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 130 loss: 1.3733814477920532. time: 14751.26ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:50:15,496 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 140 loss: 1.493083393573761. time: 14774.90ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:50:30,435 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 150 loss: 1.3696774125099183. time: 14937.30ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:50:45,540 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 160 loss: 1.2553575396537782. time: 15102.05ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:51:00,529 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 170 loss: 1.4028197050094604. time: 14986.18ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:51:15,370 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 180 loss: 1.3367117285728454. time: 14838.23ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:51:30,206 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 190 loss: 1.4591639161109924. time: 14833.45ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:51:45,010 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 200 loss: 1.4514042735099792. time: 14799.50ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:51:59,984 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 210 loss: 1.3549142718315124. time: 14970.61ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:52:14,737 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 220 loss: 1.396742832660675. time: 14749.30ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:52:29,747 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 230 loss: 1.459578037261963. time: 15006.64ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:52:44,693 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 240 loss: 1.3681164979934692. time: 14943.24ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:52:59,535 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 250 loss: 1.4000090599060058. time: 14837.99ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:53:14,526 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 260 loss: 1.421203851699829. time: 14987.62ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:53:29,297 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 270 loss: 1.341539466381073. time: 14769.47ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:53:44,397 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 280 loss: 1.4819113969802857. time: 15096.60ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:53:59,221 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 290 loss: 1.4156477332115174. time: 14820.82ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:54:14,062 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 300 loss: 1.4011789798736571. time: 14836.57ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:54:28,837 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 310 loss: 1.545214581489563. time: 14771.65ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:54:43,757 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 320 loss: 1.3890534162521362. time: 14916.68ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:54:58,532 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 330 loss: 1.4691091537475587. time: 14771.80ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:55:13,177 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 340 loss: 1.3532106399536132. time: 14641.41ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:55:28,063 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 350 loss: 1.3774832844734193. time: 14881.45ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:55:43,043 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 360 loss: 1.381729793548584. time: 14977.00ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:55:57,917 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 370 loss: 1.3985156893730164. time: 14869.82ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:56:12,852 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 380 loss: 1.444743287563324. time: 14931.78ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:56:27,655 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 390 loss: 1.3727992057800293. time: 14799.39ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:56:42,554 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 400 loss: 1.3658275723457336. time: 14894.27ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:56:57,540 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 410 loss: 1.4344772100448608. time: 14982.80ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:57:12,361 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 420 loss: 1.5039143562316895. time: 14818.19ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:57:27,327 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 430 loss: 1.3537156224250793. time: 14962.93ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:57:42,370 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 440 loss: 1.3911601185798645. time: 15040.78ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:57:57,172 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 450 loss: 1.4615123629570008. time: 14798.82ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:58:12,206 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 460 loss: 1.4166951656341553. time: 15031.38ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:58:26,921 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 470 loss: 1.3688734531402589. time: 14713.76ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:58:41,677 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 480 loss: 1.2966457843780517. time: 14752.48ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:58:56,544 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 490 loss: 1.4480827689170837. time: 14864.43ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:59:11,527 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 500 loss: 1.5584898710250854. time: 14979.18ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:59:39,326 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32mAVERAGE EVAL LOSS FOR EPOCH 5/20: 9.400857925415039\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:59:39,330 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m1.5584898710250854\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:59:40,228 \u001b[0m][\u001b[2;37mqtransform.utils.helper\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32mModel checkpoint saved to /home/mabot004/eki-transformer-dev/shakespeare_owt_benchmarking/wikitext/GPT_wikitext_2024-03-06_09:55:12__epoch:5\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:59:40,231 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[34mDEBUG\u001b[0m] - \u001b[34mNew learning rate: 0.001\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:59:40,233 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32mEPOCH: 6/20\u001b[0m\n",
      "[ \u001b[36m2024-03-06 10:59:55,318 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 10 loss: 1.6771079778671265. time: 14988.04ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 11:00:10,146 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 20 loss: 1.3965782403945923. time: 14823.94ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 11:00:25,136 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 30 loss: 1.3875458240509033. time: 14985.94ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 11:00:40,443 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 40 loss: 1.3851109862327575. time: 15304.22ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 11:00:55,409 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 50 loss: 1.4538761973381042. time: 14963.30ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 11:01:10,129 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 60 loss: 1.4134328365325928. time: 14717.04ms\u001b[0m\n",
      "[ \u001b[36m2024-03-06 11:01:25,035 \u001b[0m][\u001b[2;37mqtransform.run.train\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m  batch 70 loss: 1.3382246494293213. time: 14902.09ms\u001b[0m\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt_2_h2l2e256b64_ReBN\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      2\u001b[0m args\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39mmodel)\n\u001b[0;32m----> 3\u001b[0m \u001b[43mqtransform\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnotebook_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogging\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mINFO\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/eki-transformer-dev/qtransform/eki/lib/python3.10/site-packages/qtransform-0.0.2.dev0-py3.10.egg/qtransform/__init__.py:37\u001b[0m, in \u001b[0;36mnotebook_run\u001b[0;34m(args, loglevel)\u001b[0m\n\u001b[1;32m     35\u001b[0m cfg \u001b[38;5;241m=\u001b[39m compose(config_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfig.yaml\u001b[39m\u001b[38;5;124m\"\u001b[39m, overrides\u001b[38;5;241m=\u001b[39margs)\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28mprint\u001b[39m(cfg)\n\u001b[0;32m---> 37\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/eki-transformer-dev/qtransform/eki/lib/python3.10/site-packages/qtransform-0.0.2.dev0-py3.10.egg/qtransform/__init__.py:14\u001b[0m, in \u001b[0;36mmain\u001b[0;34m(cfg)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Run this app like amodule, Note: cfg is a Hydra config (OmegaConf Object)\"\"\"\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mqtransform\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m  __main__ \u001b[38;5;28;01mas\u001b[39;00m mn\n\u001b[0;32m---> 14\u001b[0m \u001b[43mmn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/eki-transformer-dev/qtransform/eki/lib/python3.10/site-packages/qtransform-0.0.2.dev0-py3.10.egg/qtransform/__main__.py:44\u001b[0m, in \u001b[0;36mmain\u001b[0;34m(cfg)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mcase\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m:          \n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mqtransform\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrun\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train\n\u001b[0;32m---> 44\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m  \u001b[43mtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mcase\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbench\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mqtransform\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrun\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m bench\n",
      "File \u001b[0;32m~/eki-transformer-dev/qtransform/eki/lib/python3.10/site-packages/qtransform-0.0.2.dev0-py3.10.egg/qtransform/run/train.py:114\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(cfg)\u001b[0m\n\u001b[1;32m    111\u001b[0m         model, _ \u001b[38;5;241m=\u001b[39m quantizer\u001b[38;5;241m.\u001b[39mget_quantized_model(replace_layers_later)\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;66;03m#if hasattr(log,\"trace\"): log.trace(model)\u001b[39;00m\n\u001b[0;32m--> 114\u001b[0m     last_checkpoint \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_data_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_data_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimestamp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimestamp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;66;03m# maybe subsequent jobs can be managed by hydra in the future?\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;66;03m# when this paradigm comes up more frequently we have to make this a thing ....\u001b[39;00m\n\u001b[1;32m    117\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFinished training model\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/eki-transformer-dev/qtransform/eki/lib/python3.10/site-packages/qtransform-0.0.2.dev0-py3.10.egg/qtransform/run/train.py:211\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, cfg, device, train_data_loader, eval_data_loader, optimizer, scheduler, timestamp)\u001b[0m\n\u001b[1;32m    209\u001b[0m     log\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mprof\u001b[38;5;241m.\u001b[39mkey_averages()\u001b[38;5;241m.\u001b[39mtable(sort_by\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu_time_total\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;250m \u001b[39mrow_limit\u001b[38;5;241m=\u001b[39mrow_limit)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 211\u001b[0m     metrics \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_one_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_data_loader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmini_run\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;66;03m## eval\u001b[39;00m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m epoch \u001b[38;5;241m%\u001b[39m cfg\u001b[38;5;241m.\u001b[39mrun\u001b[38;5;241m.\u001b[39meval_epoch_interval \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m eval_data_loader \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/eki-transformer-dev/qtransform/eki/lib/python3.10/site-packages/qtransform-0.0.2.dev0-py3.10.egg/qtransform/run/train.py:273\u001b[0m, in \u001b[0;36mtrain_one_epoch\u001b[0;34m(cfg, device, model, train_data, optimizer, mini_run)\u001b[0m\n\u001b[1;32m    271\u001b[0m labels \u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39mto(device_singleton\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    272\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cfg\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mcalc_loss_in_model:\n\u001b[0;32m--> 273\u001b[0m     outputs, loss \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    275\u001b[0m     outputs, _ \u001b[38;5;241m=\u001b[39m model(inputs)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/eki-transformer-dev/qtransform/eki/lib/python3.10/site-packages/qtransform-0.0.2.dev0-py3.10.egg/qtransform/model/gpt.py:153\u001b[0m, in \u001b[0;36mGPT.forward\u001b[0;34m(self, idx, targets)\u001b[0m\n\u001b[1;32m    151\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransformer\u001b[38;5;241m.\u001b[39mdropout(x)\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m block \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransformer\u001b[38;5;241m.\u001b[39mlayer:\n\u001b[0;32m--> 153\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mblock\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm_size:\n\u001b[1;32m    155\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransformer\u001b[38;5;241m.\u001b[39mln_out(x)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/eki-transformer-dev/qtransform/eki/lib/python3.10/site-packages/qtransform-0.0.2.dev0-py3.10.egg/qtransform/model/modules/__init__.py:274\u001b[0m, in \u001b[0;36mTransformerBlock.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    272\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm_size:\n\u001b[1;32m    273\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mln_1(x)\n\u001b[0;32m--> 274\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresidual1(x, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    275\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mln_2(x)\n\u001b[1;32m    276\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresidual2(x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmlp(x))\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/eki-transformer-dev/qtransform/eki/lib/python3.10/site-packages/qtransform-0.0.2.dev0-py3.10.egg/qtransform/model/modules/__init__.py:197\u001b[0m, in \u001b[0;36mCausalSelfAttention.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    193\u001b[0m     N, C, L \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39msize()\n\u001b[1;32m    194\u001b[0m     \u001b[38;5;66;03m#TODO: with torch version 2.0, output becomes nan when model is in eval mode. outside of CausalSelfAttention, mha does not return nan\u001b[39;00m\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;66;03m#      tensors during eval mode\u001b[39;00m\n\u001b[1;32m    196\u001b[0m     \u001b[38;5;66;03m#due to inference, input features can be lower than specified max context length which causes problem during attention calculation\u001b[39;00m\n\u001b[0;32m--> 197\u001b[0m     y, weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmha\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43mC\u001b[49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43mC\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mneed_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# Q, K, V, attn_mask y\u001b[39;00m\n\u001b[1;32m    198\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresid_dropout(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mc_proj(y))\n\u001b[1;32m    199\u001b[0m     \u001b[38;5;66;03m#y, weights = self.mha(x, x, x, is_causal=True) # Q, K, V, attn_mask y\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/activation.py:1189\u001b[0m, in \u001b[0;36mMultiheadAttention.forward\u001b[0;34m(self, query, key, value, key_padding_mask, need_weights, attn_mask, average_attn_weights, is_causal)\u001b[0m\n\u001b[1;32m   1175\u001b[0m     attn_output, attn_output_weights \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mmulti_head_attention_forward(\n\u001b[1;32m   1176\u001b[0m         query, key, value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed_dim, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_heads,\n\u001b[1;32m   1177\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_proj_weight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_proj_bias,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1186\u001b[0m         average_attn_weights\u001b[38;5;241m=\u001b[39maverage_attn_weights,\n\u001b[1;32m   1187\u001b[0m         is_causal\u001b[38;5;241m=\u001b[39mis_causal)\n\u001b[1;32m   1188\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1189\u001b[0m     attn_output, attn_output_weights \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmulti_head_attention_forward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1190\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_heads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1191\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43min_proj_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43min_proj_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1192\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias_k\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias_v\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_zero_attn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1193\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mout_proj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mout_proj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1194\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkey_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey_padding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1196\u001b[0m \u001b[43m        \u001b[49m\u001b[43mneed_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mneed_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1197\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattn_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1198\u001b[0m \u001b[43m        \u001b[49m\u001b[43maverage_attn_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maverage_attn_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1199\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_causal\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1200\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_first \u001b[38;5;129;01mand\u001b[39;00m is_batched:\n\u001b[1;32m   1201\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m attn_output\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m), attn_output_weights\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:5188\u001b[0m, in \u001b[0;36mmulti_head_attention_forward\u001b[0;34m(query, key, value, embed_dim_to_check, num_heads, in_proj_weight, in_proj_bias, bias_k, bias_v, add_zero_attn, dropout_p, out_proj_weight, out_proj_bias, training, key_padding_mask, need_weights, attn_mask, use_separate_proj_weight, q_proj_weight, k_proj_weight, v_proj_weight, static_k, static_v, average_attn_weights, is_causal)\u001b[0m\n\u001b[1;32m   5186\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m use_separate_proj_weight:\n\u001b[1;32m   5187\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m in_proj_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_separate_proj_weight is False but in_proj_weight is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 5188\u001b[0m     q, k, v \u001b[38;5;241m=\u001b[39m \u001b[43m_in_projection_packed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_proj_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_proj_bias\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5189\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   5190\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m q_proj_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_separate_proj_weight is True but q_proj_weight is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:4767\u001b[0m, in \u001b[0;36m_in_projection_packed\u001b[0;34m(q, k, v, w, b)\u001b[0m\n\u001b[1;32m   4765\u001b[0m     proj \u001b[38;5;241m=\u001b[39m linear(q, w, b)\n\u001b[1;32m   4766\u001b[0m     \u001b[38;5;66;03m# reshape to 3, E and not E, 3 is deliberate for better memory coalescing and keeping same order as chunk()\u001b[39;00m\n\u001b[0;32m-> 4767\u001b[0m     proj \u001b[38;5;241m=\u001b[39m \u001b[43mproj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mE\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranspose\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontiguous\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4768\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m proj[\u001b[38;5;241m0\u001b[39m], proj[\u001b[38;5;241m1\u001b[39m], proj[\u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m   4769\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   4770\u001b[0m     \u001b[38;5;66;03m# encoder-decoder attention\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/fx/traceback.py:41\u001b[0m, in \u001b[0;36mformat_stack\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [current_meta\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstack_trace\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)]\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;66;03m# fallback to traceback.format_stack()\u001b[39;00m\n\u001b[0;32m---> 41\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m traceback\u001b[38;5;241m.\u001b[39mformat_list(\u001b[43mtraceback\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract_stack\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/traceback.py:227\u001b[0m, in \u001b[0;36mextract_stack\u001b[0;34m(f, limit)\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m f \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    226\u001b[0m     f \u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39m_getframe()\u001b[38;5;241m.\u001b[39mf_back\n\u001b[0;32m--> 227\u001b[0m stack \u001b[38;5;241m=\u001b[39m \u001b[43mStackSummary\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwalk_stack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlimit\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    228\u001b[0m stack\u001b[38;5;241m.\u001b[39mreverse()\n\u001b[1;32m    229\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m stack\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/traceback.py:370\u001b[0m, in \u001b[0;36mStackSummary.extract\u001b[0;34m(klass, frame_gen, limit, lookup_lines, capture_locals)\u001b[0m\n\u001b[1;32m    367\u001b[0m name \u001b[38;5;241m=\u001b[39m co\u001b[38;5;241m.\u001b[39mco_name\n\u001b[1;32m    369\u001b[0m fnames\u001b[38;5;241m.\u001b[39madd(filename)\n\u001b[0;32m--> 370\u001b[0m \u001b[43mlinecache\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlazycache\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mf_globals\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    371\u001b[0m \u001b[38;5;66;03m# Must defer line lookups until we have called checkcache.\u001b[39;00m\n\u001b[1;32m    372\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m capture_locals:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/linecache.py:161\u001b[0m, in \u001b[0;36mlazycache\u001b[0;34m(filename, module_globals)\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Seed the cache for filename with module_globals.\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \n\u001b[1;32m    150\u001b[0m \u001b[38;5;124;03mThe module loader will be asked for the source only when getlines is\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;124;03m    filename, and the filename must not be already cached.\u001b[39;00m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m filename \u001b[38;5;129;01min\u001b[39;00m cache:\n\u001b[0;32m--> 161\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcache\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    162\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = \"gpt_2_h2l2e256b64_ReBN\"\n",
    "args.append(\"model=\"+model)\n",
    "qtransform.notebook_run(args, logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8cc5088-1641-470d-87e6-629aedef25d6",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### ReLU LayerNorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b275c7-d6d5-4765-9d2d-dc658c46b9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"gpt_2_h2l2e256b64_ReLN\"\n",
    "args.append(\"model=\"+model)\n",
    "qtransform.notebook_run(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea3d7d88-aae2-4e09-8e2c-0d303f6a829b",
   "metadata": {},
   "source": [
    "#### GELU BatchNorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f68609a-e8a1-44d0-8d2f-c33af27cb3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"gpt_2_h2l2e256b64_GeBN\"\n",
    "args.append(\"model=\"+model)\n",
    "qtransform.notebook_run(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede4be2a-17a0-45c6-97bd-f65f949f83cc",
   "metadata": {},
   "source": [
    "#### GELU LayerNorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6ece23-83de-4240-a189-f06f1f53a3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"gpt_2_h2l2e256b64_GeLN\"\n",
    "args.append(\"model=\"+model)\n",
    "qtransform.notebook_run(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f99928-b1b2-4e55-adad-c32b1a36d4c7",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cdeba56e-1b91-453a-9c50-dd93b575237f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "args_infer = [\n",
    "        \"run=infer\",\n",
    "        \"device=cuda\", \n",
    "        \"run.out_dir=out_infer\",\n",
    "        \"run.num_samples=20\", \n",
    "        \"run.max_new_tokens=100\",\n",
    "        \"run.temperature=0.8\",\n",
    "        \"run.top_k=200\",\n",
    "        \"run.start='\\n'\",\n",
    "        \"debug=True\"\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa17b29-bf39-4e44-a263-635356801009",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHECKPOINT=\"\"\n",
    "args_infer.append(\"run.from_checkpoint=\"+CHECKPOINT)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eki",
   "language": "python",
   "name": "eki"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
