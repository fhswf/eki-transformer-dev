{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "947f3a38-8a86-4e92-ba1f-23bce71d5d3e",
   "metadata": {},
   "source": [
    "### Validating our inference and benchmarking scripts based on OpenAI's GPT2 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d8ddb3d-dfe2-4a3b-89c8-a6fa0b45bb03",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import qtransform\n",
    "import logging\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "330015ad-7d74-4812-8300-570433699495",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#qtransform.notebook_run([\"run=infer\", \"run.pretrained_model=gpt2\"], logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d01c3db7-4069-4601-810b-c6b03c55ec37",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['run=bench',\n",
       " 'run.pretrained_model=gpt2',\n",
       " 'run.num_samples=1',\n",
       " 'dataset=huggingface',\n",
       " 'dataset.name=wikitext',\n",
       " 'dataset/tokenizer=tiktoken',\n",
       " 'dataset.tokenizer.encoding=\"gpt2\"',\n",
       " '+model.args.block_size=1024']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'run=bench run.pretrained_model=gpt2 run.num_samples=1 dataset=huggingface dataset.name=wikitext dataset/tokenizer=tiktoken dataset.tokenizer.encoding=\"gpt2\" +model.args.block_size=1024'.split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "280887b2-3aa6-4fbf-b751-775740cfbaf6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data': {'dtype': 'float32'}, 'device': 'cuda', 'debug': False, 'dataset': {'wrapper': 'HuggingfaceDatasetWrapper', 'module': 'huggingface', 'name': 'wikitext', 'root_path': '~/.qtransform/datasets', 'dataset_dir': ['${dataset.root_path}', '${dataset.module}', '${dataset.name}'], 'sizes': {'train': 0.0, 'eval': 0.0, 'bench': 0.0}, 'tokenizer': {'dtype': '${data.dtype}', 'meta_file': 'meta.pkl', 'wrapper': 'TikTokenizer', 'encoding': 'gpt2', 'module': 'tiktoken'}, 'dataloader': {'shuffle': True, 'num_workers': 2, 'batch_size': 12}, 'subset': 'wikitext-2-raw-v1', 'type': 'huggingface', 'splits': {'names': {'train': 'train', 'eval': 'validation', 'bench': 'test'}, 'sizes': {'train': 0.9, 'eval': 0.05, 'bench': 0.05}}, 'args': {'block_size': '${model.args.block_size}', 'cache_dir': None, 'data_column_name': 'text', 'batches': 1000, 'chunking': True, 'chunk_size': 100}}, 'seed': 1234567890, 'model': {'calc_loss_in_model': False, 'args': {'block_size': 1024}}, 'quantization': {'quantize': False}, 'pipe': '/dev/null', 'optim': {'optimizer': 'AdamW', 'args': {'learning_rate': 0.00015, 'weight_decay': 0.1, 'betas': [0.9, 0.95]}, 'scheduler': {'decay_lr': True, 'schedulers': {'1': {'name': 'StepLR', 'args': {'step_size': 1, 'gamma': 0.1}}}, 'milestones': None, 'warmup_epochs': 2}}, 'run': {'command': 'bench', 'el': 2, 'num_samples': 5, 'out_dir': '', 'profile': True, 'checkpoint_dir': 'models', 'from_checkpoint': None, 'pretrained_model': 'gpt2', 'row_limit': 10, 'onnx_model': {'path': None, 'tokenizer': {'module': 'tiktoken', 'encoding': 'gpt2', 'meta_path': None}}}}\n",
      "[ \u001b[36m2024-03-07 16:38:22,719 \u001b[0m][\u001b[2;37mnumexpr.utils\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32mNote: detected 128 virtual cores but NumExpr set to maximum of 64, check \"NUMEXPR_MAX_THREADS\" environment variable.\u001b[0m\n",
      "[ \u001b[36m2024-03-07 16:38:22,726 \u001b[0m][\u001b[2;37mnumexpr.utils\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32mNote: NumExpr detected 128 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\u001b[0m\n",
      "[ \u001b[36m2024-03-07 16:38:22,729 \u001b[0m][\u001b[2;37mnumexpr.utils\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32mNumExpr defaulting to 8 threads.\u001b[0m\n",
      "[ \u001b[36m2024-03-07 16:38:23,362 \u001b[0m][\u001b[2;37mqtransform.run.bench\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m================\u001b[0m\n",
      "[ \u001b[36m2024-03-07 16:38:23,365 \u001b[0m][\u001b[2;37mqtransform.run.bench\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32mRunning Benchmarking\u001b[0m\n",
      "[ \u001b[36m2024-03-07 16:38:23,367 \u001b[0m][\u001b[2;37mqtransform.run.bench\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m================\u001b[0m\n",
      "[ \u001b[36m2024-03-07 16:38:23,369 \u001b[0m][\u001b[2;37mqtransform.run.bench\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32mtime is: 2024-03-07_16:38:23\u001b[0m\n",
      "[ \u001b[36m2024-03-07 16:38:23,372 \u001b[0m][\u001b[2;37mqtransform\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32mDevice specified: cuda. Using device: cuda\u001b[0m\n",
      "[ \u001b[36m2024-03-07 16:38:23,378 \u001b[0m][\u001b[2;37mqtransform.run.bench\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32mnumber of torch dataloader: 2\u001b[0m\n",
      "[ \u001b[36m2024-03-07 16:38:23,688 \u001b[0m][\u001b[2;37mqtransform.dataset\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32mLoading dataset: wikitext, with encoding: gpt2 and dtype: float32\u001b[0m\n",
      "[ \u001b[36m2024-03-07 16:38:23,695 \u001b[0m][\u001b[2;37mqtransform.dataset\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32mAttempting to retrieve tokenized dataset under \"/home/makuh001/.qtransform/datasets/huggingface/wikitext/tokenized/gpt2/train-wikitext-2-raw-v1-float32.bin\"\u001b[0m\n",
      "[ \u001b[36m2024-03-07 16:38:23,699 \u001b[0m][\u001b[2;37mqtransform.dataset\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32mLoaded data has 2501647 tokens.\u001b[0m\n",
      "[ \u001b[36m2024-03-07 16:38:23,701 \u001b[0m][\u001b[2;37mqtransform.dataset\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32mAttempting to retrieve tokenized dataset under \"/home/makuh001/.qtransform/datasets/huggingface/wikitext/tokenized/gpt2/eval-wikitext-2-raw-v1-float32.bin\"\u001b[0m\n",
      "[ \u001b[36m2024-03-07 16:38:23,704 \u001b[0m][\u001b[2;37mqtransform.dataset\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32mLoaded data has 258896 tokens.\u001b[0m\n",
      "[ \u001b[36m2024-03-07 16:38:23,707 \u001b[0m][\u001b[2;37mqtransform.dataset\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32mAttempting to retrieve tokenized dataset under \"/home/makuh001/.qtransform/datasets/huggingface/wikitext/tokenized/gpt2/bench-wikitext-2-raw-v1-float32.bin\"\u001b[0m\n",
      "[ \u001b[36m2024-03-07 16:38:23,710 \u001b[0m][\u001b[2;37mqtransform.dataset\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32mLoaded data has 296271 tokens.\u001b[0m\n",
      "[ \u001b[36m2024-03-07 16:38:23,714 \u001b[0m][\u001b[2;37mqtransform.run.bench\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32mUsing pretrained model gpt2\u001b[0m\n",
      "[ \u001b[36m2024-03-07 16:38:29,912 \u001b[0m][\u001b[2;37mqtransform.dataset.tokenizer.tokenizer\u001b[0m][\u001b[33mWARNING\u001b[0m] - \u001b[33mProperty meta_file omited in config. Assuming default: \"meta.pkl\"\u001b[0m\n",
      "[ \u001b[36m2024-03-07 16:38:30,078 \u001b[0m][\u001b[2;37mqtransform.run.bench\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32mRunning Benchmark fo 5 samples\u001b[0m\n",
      "[ \u001b[36m2024-03-07 16:38:30,081 \u001b[0m][\u001b[2;37mqtransform.run.bench\u001b[0m][\u001b[33mWARNING\u001b[0m] - \u001b[33mDatalaoder length might not be correct\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2024-03-07 16:38:30 170824:170824 ActivityProfilerController.cpp:311] Completed Stage: Warm Up\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ \u001b[36m2024-03-07 16:38:34,466 \u001b[0m][\u001b[2;37mqtransform.run.bench\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32mBenchmark results: \n",
      "┌────────────────────┬───────────┬────────────┐\n",
      "│ path               │   avg_ppl │   acc_in_% │\n",
      "├────────────────────┼───────────┼────────────┤\n",
      "│ hf-pretrained-gpt2 │   189.862 │    23.7988 │\n",
      "└────────────────────┴───────────┴────────────┘\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2024-03-07 16:38:34 170824:170824 ActivityProfilerController.cpp:317] Completed Stage: Collection\n",
      "STAGE:2024-03-07 16:38:34 170824:170824 ActivityProfilerController.cpp:321] Completed Stage: Post Processing\n",
      "[W collection.cpp:700] Warning: Failed to recover relationship between all profiler and kineto events: 5249 vs. 0  reassociated. (function reassociate)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ \u001b[36m2024-03-07 16:38:35,098 \u001b[0m][\u001b[2;37mqtransform.run.bench\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[32m\n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                             cudaMalloc        43.65%        1.678s        43.65%        1.678s       4.314ms       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b           389  \n",
      "                                               cudaFree        33.93%        1.304s        33.93%        1.304s       4.064ms       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b           321  \n",
      "                                  cudaStreamSynchronize        16.08%     617.998ms        16.08%     618.053ms       7.271ms       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b            85  \n",
      "                                        cudaMemcpyAsync         5.81%     223.401ms         5.81%     223.401ms       2.628ms       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b            85  \n",
      "                                       cudaLaunchKernel         0.45%      17.142ms         0.45%      17.142ms      10.204us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b          1680  \n",
      "                                          cudaHostAlloc         0.07%       2.697ms         0.07%       2.697ms     269.700us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b            10  \n",
      "cudaOccupancyMaxActiveBlocksPerMultiprocessorWithFla...         0.01%     356.000us         0.01%     356.000us       0.324us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b          1100  \n",
      "                               cudaPointerGetAttributes         0.00%     180.000us         0.00%     180.000us      10.000us       0.000us         0.00%       0.000us       0.000us           0 b           0 b     109.00 Mb     109.00 Mb            18  \n",
      "                                  cudaStreamIsCapturing         0.00%      57.000us         0.00%      57.000us       0.148us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b           386  \n",
      "                                  cudaDeviceSynchronize         0.00%      28.000us         0.00%      28.000us      28.000us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b             1  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 3.844s\n",
      "Self CUDA time total: 1.506s\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "args_benchmarking = ['run=bench',\n",
    " 'run.pretrained_model=gpt2',\n",
    " 'run.num_samples=5',\n",
    " 'dataset=huggingface',\n",
    " 'dataset.name=wikitext',\n",
    " 'dataset.subset=wikitext-2-raw-v1',\n",
    " 'dataset/tokenizer=tiktoken',\n",
    " 'dataset.tokenizer.encoding=\"gpt2\"',\n",
    " '+model.args.block_size=1024']\n",
    "qtransform.notebook_run(args_benchmarking,logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39e0f82e-fa62-4e18-8ced-9fa92779b9a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def measure_perplexity(logits: torch.Tensor, labels: torch.Tensor):\n",
    "    #cross entropy either expects the probabilities of tokens or a list of tokens\n",
    "    #(https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html)\n",
    "    return torch.exp(F.cross_entropy(logits.view(-1, logits.size(-1)), labels.view(-1), ignore_index=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6add984-d373-43c2-8b35-0ceafd77f5c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "labels = torch.rand(3,8,16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af085638-aee9-49f1-9ddd-883800a47a91",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[5.3237e-01, 9.4450e-01, 2.2480e-02, 2.6777e-01, 7.4107e-01,\n",
       "          9.7566e-01, 4.9895e-01, 8.0610e-01, 9.6529e-01, 1.2113e-01,\n",
       "          2.1593e-01, 5.1844e-01, 2.8345e-01, 5.5469e-01, 4.0212e-01,\n",
       "          9.3912e-01],\n",
       "         [9.8756e-01, 4.3164e-02, 8.7322e-02, 4.3465e-01, 6.0527e-01,\n",
       "          8.3735e-01, 4.5197e-01, 6.8085e-01, 7.6600e-01, 1.9580e-01,\n",
       "          1.6626e-01, 3.3511e-01, 2.6638e-01, 9.3222e-01, 5.4504e-01,\n",
       "          7.4120e-01],\n",
       "         [4.8294e-01, 2.9383e-01, 9.0077e-01, 6.3442e-01, 1.9574e-01,\n",
       "          6.0947e-01, 2.0018e-01, 9.5357e-01, 7.2274e-01, 3.2522e-01,\n",
       "          7.9905e-01, 1.0815e-01, 2.2052e-01, 9.4270e-01, 4.5376e-02,\n",
       "          2.5447e-01],\n",
       "         [3.4326e-01, 8.7107e-01, 3.0462e-01, 4.5464e-01, 2.6759e-01,\n",
       "          6.0171e-01, 2.6769e-01, 7.5461e-01, 4.5220e-01, 8.8607e-01,\n",
       "          5.1806e-01, 7.8535e-01, 1.3931e-01, 7.0787e-01, 1.7979e-01,\n",
       "          8.3452e-01],\n",
       "         [9.1938e-02, 8.6747e-01, 3.6445e-02, 9.2946e-01, 3.9016e-01,\n",
       "          5.4061e-01, 5.8440e-01, 7.7753e-01, 4.5384e-02, 5.5275e-01,\n",
       "          4.0430e-01, 9.4716e-01, 5.6008e-01, 4.2840e-01, 7.0294e-01,\n",
       "          5.8515e-01],\n",
       "         [6.5225e-01, 8.6103e-01, 9.3971e-01, 6.4551e-01, 7.3155e-01,\n",
       "          3.7013e-01, 3.5849e-01, 3.3469e-01, 4.7557e-01, 1.5033e-01,\n",
       "          2.6377e-01, 7.5192e-01, 9.2193e-01, 6.1390e-01, 3.8821e-01,\n",
       "          3.1835e-02],\n",
       "         [6.5300e-01, 6.2169e-01, 1.9798e-01, 5.2877e-01, 9.1219e-01,\n",
       "          2.5535e-01, 6.5446e-01, 9.6209e-01, 3.1434e-01, 2.8940e-01,\n",
       "          5.9426e-01, 2.3015e-01, 7.8926e-02, 1.3203e-01, 1.1287e-01,\n",
       "          6.7847e-01],\n",
       "         [6.3838e-01, 3.9483e-01, 1.9592e-01, 8.0350e-01, 3.4923e-01,\n",
       "          2.8230e-01, 8.9632e-01, 7.6878e-01, 6.7636e-02, 1.9839e-01,\n",
       "          7.8111e-02, 9.2216e-02, 9.5366e-01, 6.6551e-01, 8.8089e-01,\n",
       "          3.0590e-01]],\n",
       "\n",
       "        [[1.5270e-01, 7.3621e-01, 1.7979e-01, 8.9812e-01, 5.2094e-01,\n",
       "          3.5478e-01, 7.2161e-01, 2.0002e-02, 4.7117e-01, 8.9174e-01,\n",
       "          8.0615e-01, 7.2639e-01, 9.0085e-01, 3.0850e-01, 4.5888e-02,\n",
       "          9.0449e-01],\n",
       "         [2.4798e-01, 7.8167e-03, 3.5195e-01, 2.5596e-01, 9.2956e-01,\n",
       "          5.3840e-01, 6.6960e-01, 4.0439e-01, 1.2615e-02, 9.8311e-01,\n",
       "          6.0944e-01, 8.8507e-01, 2.8070e-01, 5.1428e-01, 8.5909e-01,\n",
       "          9.0753e-01],\n",
       "         [1.5546e-01, 1.5187e-02, 7.9077e-01, 9.0745e-01, 2.0688e-01,\n",
       "          6.2386e-01, 6.8610e-01, 9.2801e-01, 2.0381e-01, 9.8279e-02,\n",
       "          3.3928e-02, 8.1852e-01, 2.6056e-01, 6.8539e-02, 8.7593e-01,\n",
       "          3.7185e-01],\n",
       "         [8.5840e-01, 3.4392e-01, 1.6355e-01, 4.5846e-01, 9.8745e-01,\n",
       "          1.7661e-02, 4.8859e-01, 3.6547e-01, 9.9862e-01, 3.9293e-01,\n",
       "          4.8932e-01, 7.2870e-01, 1.1054e-01, 8.1546e-01, 2.2654e-01,\n",
       "          8.3433e-03],\n",
       "         [3.7669e-01, 8.1653e-01, 3.3782e-01, 7.6112e-01, 6.9765e-01,\n",
       "          6.8141e-01, 4.9641e-01, 2.3796e-01, 7.6627e-01, 8.1416e-01,\n",
       "          6.6252e-01, 7.7490e-01, 8.3176e-01, 7.0870e-01, 9.9345e-02,\n",
       "          9.3063e-01],\n",
       "         [6.9096e-02, 5.7374e-01, 7.1690e-01, 4.2862e-01, 3.1858e-01,\n",
       "          3.1691e-02, 7.7333e-01, 9.9241e-01, 8.5373e-01, 8.0403e-01,\n",
       "          4.1755e-01, 8.8549e-01, 8.0833e-01, 7.4316e-02, 3.9700e-01,\n",
       "          7.8881e-02],\n",
       "         [8.8814e-01, 9.4623e-01, 5.1919e-01, 2.3854e-01, 1.4509e-01,\n",
       "          6.9461e-01, 6.3263e-01, 3.6013e-02, 1.9704e-01, 3.8807e-01,\n",
       "          3.3482e-01, 3.2429e-01, 4.6131e-02, 5.9138e-02, 3.3613e-01,\n",
       "          7.1786e-01],\n",
       "         [8.0477e-01, 8.3794e-01, 7.5390e-01, 9.6049e-01, 4.8090e-01,\n",
       "          6.5132e-01, 3.7868e-02, 8.2227e-01, 3.4368e-01, 7.8343e-01,\n",
       "          1.1184e-01, 3.9024e-01, 2.4097e-01, 6.7100e-01, 8.3198e-01,\n",
       "          7.4143e-02]],\n",
       "\n",
       "        [[3.3285e-01, 6.9289e-01, 9.8675e-01, 7.1486e-01, 1.6887e-01,\n",
       "          7.3889e-01, 3.2446e-01, 9.9751e-01, 1.1173e-01, 8.7908e-01,\n",
       "          3.3289e-01, 7.0487e-01, 9.7932e-01, 5.9317e-01, 1.5416e-01,\n",
       "          1.5370e-01],\n",
       "         [7.7866e-01, 3.5388e-01, 2.9169e-01, 1.2827e-01, 6.7891e-02,\n",
       "          8.3788e-01, 5.4677e-02, 7.8348e-01, 6.8095e-01, 9.6958e-01,\n",
       "          9.5431e-01, 5.5543e-01, 4.8491e-01, 8.3476e-01, 6.3946e-02,\n",
       "          5.6407e-01],\n",
       "         [1.9751e-02, 7.4673e-01, 8.5069e-01, 5.6639e-01, 4.7340e-01,\n",
       "          4.5355e-01, 5.4431e-01, 5.0802e-01, 3.9507e-01, 6.4254e-01,\n",
       "          6.6791e-02, 4.7973e-01, 6.0921e-01, 7.5021e-01, 2.7454e-01,\n",
       "          8.6611e-01],\n",
       "         [8.3528e-01, 9.7790e-01, 2.4905e-01, 9.6628e-01, 6.1667e-01,\n",
       "          3.3177e-01, 8.2354e-01, 8.9034e-01, 4.6639e-01, 9.2662e-01,\n",
       "          3.1545e-01, 8.9394e-01, 1.1548e-01, 9.2873e-02, 7.4060e-01,\n",
       "          7.4233e-01],\n",
       "         [4.3427e-01, 6.7675e-01, 6.0239e-01, 5.7863e-01, 6.3190e-01,\n",
       "          4.7438e-01, 6.3674e-01, 9.7904e-01, 2.6942e-01, 3.9650e-01,\n",
       "          7.3800e-01, 4.4573e-02, 9.2706e-01, 9.6817e-01, 9.0798e-01,\n",
       "          1.9291e-01],\n",
       "         [5.5817e-01, 4.5044e-01, 4.6927e-01, 4.9298e-02, 2.2319e-01,\n",
       "          4.0836e-01, 5.3926e-01, 4.5066e-01, 1.7821e-01, 2.8043e-01,\n",
       "          3.4394e-01, 9.9238e-01, 2.8871e-01, 5.0294e-01, 5.7777e-01,\n",
       "          6.8358e-01],\n",
       "         [7.1791e-01, 8.0102e-01, 4.3721e-01, 6.2468e-01, 1.2271e-01,\n",
       "          6.4301e-01, 1.9606e-01, 7.7183e-01, 3.9948e-01, 7.0435e-01,\n",
       "          6.1704e-01, 5.1400e-02, 4.4434e-01, 6.2593e-01, 9.2210e-02,\n",
       "          1.7040e-01],\n",
       "         [3.8152e-01, 4.9628e-02, 3.8468e-01, 9.2512e-04, 4.6814e-01,\n",
       "          6.2532e-01, 5.8416e-01, 8.6094e-01, 6.5693e-01, 7.3194e-01,\n",
       "          7.8293e-01, 3.8110e-01, 8.1298e-01, 8.6670e-01, 2.5788e-01,\n",
       "          3.4162e-01]]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11903bf5-ed21-45a0-b238-6aaf28e0f593",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 7, 16])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[..., :-1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a67855e-8c13-453d-92df-a6873ec792a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eki",
   "language": "python",
   "name": "eki"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
